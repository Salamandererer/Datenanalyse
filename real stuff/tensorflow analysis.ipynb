{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "import tensorboard\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend\n",
    "import datetime\n",
    "\n",
    "from packaging import version\n",
    "from linkmethods import get_target, get_backlink_views\n",
    "from keras.layers import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.11.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \"This notebook requires TensorFlow 2.0 or above.\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "article = \"Data_Science\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#defining a cutoff, a lower cutoff provides a lower difference across all the input data. thus probably more accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cutoff = -512"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_main = get_target(article)\n",
    "bl_views = get_backlink_views(article, get_target(article))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#getting the Data and target data for the article, then printing them both to get a look at them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = np.array(bl_views)[:,cutoff:-1]\n",
    "print(data)\n",
    "data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target = np.array(df_main.views, dtype=float)[cutoff:-1]\n",
    "target = np.array([np.copy(target) for _ in range((data.shape[0]))])\n",
    "print(target)\n",
    "target.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#the loss function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def smape(tftarget, tfforecast):\n",
    "    denominator = tf.reduce_sum(tf.abs(tftarget)+tf.abs(tfforecast))\n",
    "    if tf.reduce_sum(tftarget)+tf.reduce_sum(tfforecast) == 0:\n",
    "        return tf.cast(1.0,tf.float64)\n",
    "    result = (2/len(tftarget)) * tf.cast(tf.reduce_sum(tf.abs(tftarget - tfforecast))/denominator,tf.float64)\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model has the size of the data you input into."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the model.\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(Input(shape=-cutoff-1)) # Input tensor\n",
    "model.add(Dense(units=-cutoff-1)) # hidden layer 1,\n",
    "model.add(Activation(activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss=smape,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#plotting the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"my_first_model.png\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#normalizing the data to even out the values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predata = sklearn.preprocessing.normalize(data,norm=\"l1\")\n",
    "pretarget = sklearn.preprocessing.normalize(target,norm=\"l1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Separate the test data\n",
    "x, x_test, y, y_test = train_test_split(predata, pretarget, test_size=0.15, shuffle=True)\n",
    "\n",
    "# Split the remaining data to train and validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.15, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#running this cell will make the NN run with the data that it has done progess on again!\n",
    "#define the model again for a clean start."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor=\"accuracy\",patience=150, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=4,\n",
    "    epochs=150,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=early_stop)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def display_learning_curves(history):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(19, 11))\n",
    "\n",
    "    axs[0,0].plot(history.history[\"loss\"])\n",
    "    axs[0,0].legend([\"train\", \"test\"], loc=\"upper right\")\n",
    "    axs[0,0].set_xlabel(\"Epochs\")\n",
    "    axs[0,0].set_ylabel(\"Loss\")\n",
    "\n",
    "    axs[0,1].plot(history.history[\"accuracy\"])\n",
    "    axs[0,1].legend([\"train\", \"test\"], loc=\"upper right\")\n",
    "    axs[0,1].set_xlabel(\"Epochs\")\n",
    "    axs[0,1].set_ylabel(\"Accuracy\")\n",
    "\n",
    "    axs[1,0].plot(history.history[\"val_loss\"])\n",
    "    axs[1,0].legend([\"train\", \"test\"], loc=\"upper right\")\n",
    "    axs[1,0].set_xlabel(\"Epochs\")\n",
    "    axs[1,0].set_ylabel(\"val_loss\")\n",
    "\n",
    "    axs[1,1].plot(history.history[\"val_accuracy\"])\n",
    "    axs[1,1].legend([\"train\", \"test\"], loc=\"upper right\")\n",
    "    axs[1,1].set_xlabel(\"Epochs\")\n",
    "    axs[1,1].set_ylabel(\"val_Accuracy\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#plotting the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_learning_curves(history)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#getting the weights used for this run"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weights = model.get_weights()\n",
    "print(sum(history.history['loss']) / len(history.history['loss']))\n",
    "weights"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
